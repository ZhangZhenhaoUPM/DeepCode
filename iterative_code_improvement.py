#!/usr/bin/env python3
"""
Iterative Code Improvement Workflow

ä½¿ç”¨Gemini CLIå’ŒCodex CLIè¿›è¡Œäº¤å‰å®¡é˜…å’Œè¿­ä»£æ”¹è¿›ï¼š
1. ä¸¤ä¸ªAIå·¥å…·ç‹¬ç«‹å®¡é˜…ä»£ç 
2. æ±‡æ€»å®¡é˜…ç»“æœï¼Œè®¡ç®—å…±è¯†åˆ†æ•°
3. æ ¹æ®å…±è¯†é—®é¢˜è¿›è¡Œä»£ç ä¿®æ”¹
4. é‡æ–°å®¡é˜…éªŒè¯æ”¹è¿›
5. é‡å¤ç›´åˆ°è¾¾åˆ°ç›®æ ‡è´¨é‡

Features:
- åŒAIäº¤å‰éªŒè¯
- å…±è¯†é—®é¢˜ä¼˜å…ˆä¿®å¤
- è¿­ä»£æ”¹è¿›ç›´åˆ°è¾¾æ ‡
- å®Œæ•´çš„å®¡é˜…å’Œä¿®æ”¹å†å²
"""

import asyncio
import subprocess
import shutil
import json
from pathlib import Path
from datetime import datetime
from typing import Dict, List, Any


class IterativeCodeImprover:
    """è¿­ä»£ä»£ç æ”¹è¿›å™¨"""

    def __init__(
        self,
        code_directory: str,
        target_score: float = 8.0,
        max_iterations: int = 5
    ):
        """
        åˆå§‹åŒ–

        Args:
            code_directory: ä»£ç ç›®å½•è·¯å¾„
            target_score: ç›®æ ‡è´¨é‡åˆ†æ•° (0-10)
            max_iterations: æœ€å¤§è¿­ä»£æ¬¡æ•°
        """
        self.code_directory = Path(code_directory)
        self.target_score = target_score
        self.max_iterations = max_iterations

        # åˆ›å»ºè¾“å‡ºç›®å½•
        self.output_dir = self.code_directory.parent / "iterative_reviews"
        self.output_dir.mkdir(parents=True, exist_ok=True)

        # å®¡é˜…å†å²
        self.review_history = []

    def print_banner(self, text: str, char: str = "="):
        """æ‰“å°æ¨ªå¹…"""
        print("\n" + char * 70)
        print(f"  {text}")
        print(char * 70 + "\n")

    def check_tools_available(self) -> Dict[str, bool]:
        """æ£€æŸ¥å·¥å…·å¯ç”¨æ€§"""
        self.print_banner("ğŸ”§ Checking Available Tools")

        tools = {
            "gemini": shutil.which("gemini") is not None,
            "codex": shutil.which("codex") is not None
        }

        print(f"âœ… Gemini CLI: {'Available' if tools['gemini'] else 'Not Found'}")
        print(f"âœ… Codex CLI:  {'Available' if tools['codex'] else 'Not Found'}")

        if not tools["gemini"] and not tools["codex"]:
            print("\nâŒ Error: No review tools available!")
            print("   Install at least one: gemini or codex CLI")
            return tools

        if not tools["gemini"]:
            print("\nâš ï¸  Warning: Gemini CLI not found, using Codex only")
        if not tools["codex"]:
            print("\nâš ï¸  Warning: Codex CLI not found, using Gemini only")

        return tools

    def run_gemini_review(self, iteration: int) -> Dict[str, Any]:
        """è¿è¡ŒGeminiå®¡é˜…"""
        print("\nğŸ“Š Running Gemini CLI Review...")

        prompt = """Review all Python files in this directory comprehensively.

For each file, provide:
1. Code quality score (0-10)
2. Issues found with severity (CRITICAL/HIGH/MEDIUM/LOW) and line numbers
3. Specific recommendations for improvement

Then provide:
- Overall average score across all files
- Top 5 most critical issues that need fixing
- Summary of code quality

Format as JSON with this structure:
{
  "files": [
    {
      "path": "file.py",
      "score": 7.5,
      "issues": [
        {"severity": "HIGH", "line": 10, "description": "...", "recommendation": "..."}
      ]
    }
  ],
  "overall_score": 7.2,
  "critical_issues": [
    {"file": "file.py", "line": 10, "issue": "...", "severity": "HIGH"}
  ],
  "summary": "..."
}"""

        try:
            result = subprocess.run(
                ["gemini", "-p", prompt, "--include-directories", str(self.code_directory)],
                capture_output=True,
                text=True,
                timeout=180
            )

            if result.returncode == 0:
                # ä¿å­˜å®Œæ•´è¾“å‡º
                output_file = self.output_dir / f"iteration_{iteration}_gemini_raw.txt"
                with open(output_file, "w", encoding="utf-8") as f:
                    f.write(result.stdout)

                # å°è¯•è§£æJSON
                try:
                    # æå–JSONéƒ¨åˆ†
                    output = result.stdout
                    if "```json" in output:
                        json_start = output.find("```json") + 7
                        json_end = output.find("```", json_start)
                        json_str = output[json_start:json_end].strip()
                    elif "{" in output:
                        json_start = output.find("{")
                        json_end = output.rfind("}") + 1
                        json_str = output[json_start:json_end]
                    else:
                        json_str = output

                    review_data = json.loads(json_str)
                    print(f"   âœ… Gemini review completed")
                    print(f"   ğŸ“Š Overall Score: {review_data.get('overall_score', 'N/A')}/10")
                    return {
                        "status": "success",
                        "tool": "gemini",
                        "data": review_data,
                        "raw_output": output
                    }

                except json.JSONDecodeError as e:
                    print(f"   âš ï¸  JSON parsing failed: {e}")
                    print(f"   ğŸ“„ Using raw text analysis")
                    return {
                        "status": "partial",
                        "tool": "gemini",
                        "data": self.parse_text_review(result.stdout),
                        "raw_output": result.stdout
                    }
            else:
                print(f"   âŒ Gemini failed: {result.stderr}")
                return {"status": "failed", "tool": "gemini", "error": result.stderr}

        except subprocess.TimeoutExpired:
            print(f"   âš ï¸  Gemini timeout")
            return {"status": "failed", "tool": "gemini", "error": "Timeout"}
        except Exception as e:
            print(f"   âŒ Error: {e}")
            return {"status": "failed", "tool": "gemini", "error": str(e)}

    def run_codex_review(self, iteration: int) -> Dict[str, Any]:
        """è¿è¡ŒCodexå®¡é˜…"""
        print("\nğŸ¤– Running Codex CLI Review...")

        prompt = """Review all Python files in this directory comprehensively.

For each file, provide:
1. Code quality score (0-10)
2. Issues found with severity (CRITICAL/HIGH/MEDIUM/LOW) and specific line numbers
3. Concrete recommendations for improvement

Then provide:
- Overall average score across all files
- Top 5 most critical issues that need immediate fixing
- Summary of overall code quality

Format as JSON with this structure:
{
  "files": [
    {
      "path": "file.py",
      "score": 7.5,
      "issues": [
        {"severity": "HIGH", "line": 10, "description": "...", "recommendation": "..."}
      ]
    }
  ],
  "overall_score": 7.2,
  "critical_issues": [
    {"file": "file.py", "line": 10, "issue": "...", "severity": "HIGH"}
  ],
  "summary": "..."
}"""

        try:
            result = subprocess.run(
                ["codex", "exec", prompt],
                cwd=str(self.code_directory),
                capture_output=True,
                text=True,
                timeout=180
            )

            output = result.stdout + result.stderr

            # æ£€æŸ¥è®¢é˜…é—®é¢˜
            if "upgrade to Plus" in output:
                print(f"   âš ï¸  Codex requires ChatGPT Plus subscription")
                return {"status": "failed", "tool": "codex", "error": "Requires Plus"}

            # ä¿å­˜å®Œæ•´è¾“å‡º
            output_file = self.output_dir / f"iteration_{iteration}_codex_raw.txt"
            with open(output_file, "w", encoding="utf-8") as f:
                f.write(output)

            # å°è¯•è§£æJSON
            try:
                # æå–JSONéƒ¨åˆ†ï¼ˆCodexè¾“å‡ºåœ¨æœ€åï¼‰
                if "```json" in output:
                    json_start = output.find("```json") + 7
                    json_end = output.find("```", json_start)
                    json_str = output[json_start:json_end].strip()
                elif "{" in output:
                    # æ‰¾åˆ°æœ€åä¸€ä¸ªå®Œæ•´çš„JSONå¯¹è±¡
                    json_start = output.rfind("{")
                    json_end = output.rfind("}") + 1
                    json_str = output[json_start:json_end]
                else:
                    json_str = output

                review_data = json.loads(json_str)
                print(f"   âœ… Codex review completed")
                print(f"   ğŸ“Š Overall Score: {review_data.get('overall_score', 'N/A')}/10")
                return {
                    "status": "success",
                    "tool": "codex",
                    "data": review_data,
                    "raw_output": output
                }

            except json.JSONDecodeError as e:
                print(f"   âš ï¸  JSON parsing failed: {e}")
                print(f"   ğŸ“„ Using raw text analysis")
                return {
                    "status": "partial",
                    "tool": "codex",
                    "data": self.parse_text_review(output),
                    "raw_output": output
                }

        except subprocess.TimeoutExpired:
            print(f"   âš ï¸  Codex timeout")
            return {"status": "failed", "tool": "codex", "error": "Timeout"}
        except Exception as e:
            print(f"   âŒ Error: {e}")
            return {"status": "failed", "tool": "codex", "error": str(e)}

    def parse_text_review(self, text: str) -> Dict[str, Any]:
        """ä»æ–‡æœ¬ä¸­è§£æå®¡é˜…ç»“æœï¼ˆfallbackï¼‰"""
        import re

        # å°è¯•æå–åˆ†æ•°
        scores = re.findall(r'score[:\s]+(\d+(?:\.\d+)?)/10', text, re.IGNORECASE)
        avg_score = sum(float(s) for s in scores) / len(scores) if scores else 5.0

        # å°è¯•æå–é—®é¢˜
        issues = []
        severity_pattern = r'(CRITICAL|HIGH|MEDIUM|LOW)[:\s]+(.*?)(?=\n|$)'
        matches = re.findall(severity_pattern, text, re.IGNORECASE)

        for severity, description in matches:
            issues.append({
                "severity": severity.upper(),
                "description": description.strip()
            })

        return {
            "overall_score": avg_score,
            "critical_issues": issues[:5],  # Top 5
            "summary": "Parsed from text output"
        }

    def generate_consensus_report(
        self,
        gemini_result: Dict[str, Any],
        codex_result: Dict[str, Any],
        iteration: int
    ) -> Dict[str, Any]:
        """ç”Ÿæˆå…±è¯†æŠ¥å‘Š"""
        self.print_banner(f"ğŸ“‹ Generating Consensus Report - Iteration {iteration}")

        consensus = {
            "iteration": iteration,
            "timestamp": datetime.now().isoformat(),
            "gemini_status": gemini_result["status"],
            "codex_status": codex_result["status"],
            "scores": {},
            "consensus_issues": [],
            "average_score": 0.0
        }

        # æå–åˆ†æ•°
        scores = []
        if gemini_result["status"] in ["success", "partial"]:
            gemini_score = gemini_result["data"].get("overall_score", 0)
            consensus["scores"]["gemini"] = gemini_score
            scores.append(gemini_score)
            print(f"   Gemini Score: {gemini_score}/10")

        if codex_result["status"] in ["success", "partial"]:
            codex_score = codex_result["data"].get("overall_score", 0)
            consensus["scores"]["codex"] = codex_score
            scores.append(codex_score)
            print(f"   Codex Score:  {codex_score}/10")

        if scores:
            consensus["average_score"] = sum(scores) / len(scores)
            print(f"\n   ğŸ“Š Consensus Score: {consensus['average_score']:.2f}/10")

        # æŸ¥æ‰¾å…±è¯†é—®é¢˜ï¼ˆä¸¤ä¸ªå·¥å…·éƒ½å‘ç°çš„é—®é¢˜ï¼‰
        if (gemini_result["status"] in ["success", "partial"] and
            codex_result["status"] in ["success", "partial"]):

            gemini_issues = gemini_result["data"].get("critical_issues", [])
            codex_issues = codex_result["data"].get("critical_issues", [])

            print(f"\n   ğŸ” Analyzing consensus issues...")
            print(f"   Gemini found: {len(gemini_issues)} critical issues")
            print(f"   Codex found:  {len(codex_issues)} critical issues")

            # ç®€å•çš„å…³é”®è¯åŒ¹é…æ¥æŸ¥æ‰¾å…±è¯†
            consensus_issues = []
            for g_issue in gemini_issues:
                g_desc = str(g_issue).lower()
                for c_issue in codex_issues:
                    c_desc = str(c_issue).lower()
                    # æ£€æŸ¥æ˜¯å¦æœ‰å…±åŒçš„å…³é”®è¯
                    common_keywords = ["device", "gpu", "cuda", "hard-coded", "hardcoded",
                                     "eval", "train", "mode", "dropout", "error handling",
                                     "exception", "validation"]
                    for keyword in common_keywords:
                        if keyword in g_desc and keyword in c_desc:
                            consensus_issues.append({
                                "keyword": keyword,
                                "gemini_finding": g_issue,
                                "codex_finding": c_issue,
                                "priority": "HIGH"
                            })
                            break

            consensus["consensus_issues"] = consensus_issues
            print(f"   âœ… Found {len(consensus_issues)} consensus issues")

        # ä¿å­˜æŠ¥å‘Š
        report_file = self.output_dir / f"iteration_{iteration}_consensus.json"
        with open(report_file, "w", encoding="utf-8") as f:
            json.dump(consensus, f, indent=2, ensure_ascii=False)

        # ç”Ÿæˆå¯è¯»æŠ¥å‘Š
        readable_file = self.output_dir / f"iteration_{iteration}_consensus.md"
        self.generate_readable_consensus_report(consensus, readable_file)

        print(f"   ğŸ’¾ Report saved: {report_file}")

        return consensus

    def generate_readable_consensus_report(self, consensus: Dict[str, Any], output_file: Path):
        """ç”Ÿæˆå¯è¯»çš„å…±è¯†æŠ¥å‘Š"""
        with open(output_file, "w", encoding="utf-8") as f:
            f.write(f"# Cross-Review Consensus Report\n\n")
            f.write(f"**Iteration:** {consensus['iteration']}\n")
            f.write(f"**Generated:** {consensus['timestamp']}\n\n")

            f.write(f"## Quality Scores\n\n")
            if "gemini" in consensus["scores"]:
                f.write(f"- **Gemini Score:** {consensus['scores']['gemini']}/10\n")
            if "codex" in consensus["scores"]:
                f.write(f"- **Codex Score:** {consensus['scores']['codex']}/10\n")
            f.write(f"- **Average Score:** {consensus['average_score']:.2f}/10\n\n")

            if consensus["consensus_issues"]:
                f.write(f"## Consensus Issues ({len(consensus['consensus_issues'])})\n\n")
                f.write("These issues were identified by both AI tools:\n\n")

                for i, issue in enumerate(consensus["consensus_issues"], 1):
                    f.write(f"### {i}. {issue['keyword'].title()} Issue\n\n")
                    f.write(f"**Priority:** {issue['priority']}\n\n")
                    f.write(f"**Gemini Finding:**\n")
                    f.write(f"```\n{json.dumps(issue['gemini_finding'], indent=2)}\n```\n\n")
                    f.write(f"**Codex Finding:**\n")
                    f.write(f"```\n{json.dumps(issue['codex_finding'], indent=2)}\n```\n\n")

    async def apply_improvements(self, consensus: Dict[str, Any], iteration: int) -> bool:
        """åº”ç”¨æ”¹è¿›ï¼ˆä½¿ç”¨ä¸¤ä¸ªAIååŒä¿®æ”¹ä»£ç ï¼‰"""
        self.print_banner(f"ğŸ”§ Applying Code Improvements - Iteration {iteration}")

        if not consensus["consensus_issues"]:
            print("   â„¹ï¸  No consensus issues to fix")
            return False

        print(f"   ğŸ“ Found {len(consensus['consensus_issues'])} consensus issues to fix")

        # ä¸ºæ¯ä¸ªå…±è¯†é—®é¢˜ç”Ÿæˆä¿®å¤æç¤º
        for i, issue in enumerate(consensus["consensus_issues"], 1):
            print(f"\n   Fixing issue {i}/{len(consensus['consensus_issues'])}: {issue['keyword']}")

            # æ„å»ºä¿®å¤æç¤º
            fix_prompt = f"""Fix the following issue in the codebase:

Issue: {issue['keyword']}

Gemini identified: {json.dumps(issue['gemini_finding'], indent=2)}
Codex identified: {json.dumps(issue['codex_finding'], indent=2)}

Please:
1. Locate the relevant files and lines
2. Apply the necessary fixes
3. Ensure the fix follows best practices
4. Preserve existing functionality

Make the changes directly to the files."""

            # ä½¿ç”¨Codexè¿›è¡Œä¿®æ”¹ï¼ˆå¦‚æœå¯ç”¨ï¼Œä½¿ç”¨workspace-writeæ¨¡å¼ï¼‰
            try:
                result = subprocess.run(
                    ["codex", "exec", "--sandbox", "workspace-write", fix_prompt],
                    cwd=str(self.code_directory),
                    capture_output=True,
                    text=True,
                    timeout=120
                )

                output = result.stdout + result.stderr

                if "upgrade to Plus" in output:
                    print(f"   âš ï¸  Codex requires Plus subscription")
                    continue

                # æ£€æŸ¥æ˜¯å¦æˆåŠŸåº”ç”¨ä¿®æ”¹
                if "file update:" in output.lower() or "diff" in output.lower():
                    print(f"   âœ… Applied fix for: {issue['keyword']}")
                else:
                    print(f"   âš ï¸  Fix may not have been applied for: {issue['keyword']}")

            except Exception as e:
                print(f"   âŒ Failed to apply fix: {e}")
                continue

        print(f"\n   ğŸ‰ Completed applying improvements")
        return True

    async def run_iteration(self, iteration: int, tools: Dict[str, bool]) -> Dict[str, Any]:
        """è¿è¡Œä¸€æ¬¡è¿­ä»£"""
        self.print_banner(f"ğŸ”„ Iteration {iteration}/{self.max_iterations}", "=")

        # è¿è¡Œä¸¤ä¸ªå·¥å…·çš„å®¡é˜…
        gemini_result = {"status": "skipped", "tool": "gemini"}
        codex_result = {"status": "skipped", "tool": "codex"}

        if tools["gemini"]:
            gemini_result = self.run_gemini_review(iteration)

        if tools["codex"]:
            codex_result = self.run_codex_review(iteration)

        # ç”Ÿæˆå…±è¯†æŠ¥å‘Š
        consensus = self.generate_consensus_report(gemini_result, codex_result, iteration)

        # ä¿å­˜åˆ°å†å²
        self.review_history.append(consensus)

        # æ£€æŸ¥æ˜¯å¦è¾¾åˆ°ç›®æ ‡
        if consensus["average_score"] >= self.target_score:
            print(f"\n   ğŸ¯ Target score {self.target_score} reached!")
            return consensus

        # å¦‚æœæœªè¾¾åˆ°ç›®æ ‡ä¸”ä¸æ˜¯æœ€åä¸€æ¬¡è¿­ä»£ï¼Œåº”ç”¨æ”¹è¿›
        if iteration < self.max_iterations:
            improvements_applied = await self.apply_improvements(consensus, iteration)
            if not improvements_applied:
                print(f"\n   â„¹ï¸  No improvements to apply")

        return consensus

    async def run(self):
        """è¿è¡Œå®Œæ•´çš„è¿­ä»£æ”¹è¿›æµç¨‹"""
        self.print_banner("ğŸš€ Starting Iterative Code Improvement Workflow", "=")

        print(f"ğŸ“ Code Directory: {self.code_directory}")
        print(f"ğŸ¯ Target Score: {self.target_score}/10")
        print(f"ğŸ”„ Max Iterations: {self.max_iterations}")

        # æ£€æŸ¥å·¥å…·å¯ç”¨æ€§
        tools = self.check_tools_available()
        if not tools["gemini"] and not tools["codex"]:
            print("\nâŒ Cannot proceed without review tools")
            return

        # è¿­ä»£æ”¹è¿›
        for iteration in range(1, self.max_iterations + 1):
            consensus = await self.run_iteration(iteration, tools)

            if consensus["average_score"] >= self.target_score:
                break

            if iteration < self.max_iterations:
                print(f"\n   â³ Waiting 5 seconds before next iteration...")
                await asyncio.sleep(5)

        # ç”Ÿæˆæœ€ç»ˆæŠ¥å‘Š
        self.generate_final_report()

    def generate_final_report(self):
        """ç”Ÿæˆæœ€ç»ˆæŠ¥å‘Š"""
        self.print_banner("ğŸ“Š Final Report", "=")

        if not self.review_history:
            print("No review history available")
            return

        # åˆ†æ•°è¶‹åŠ¿
        print("\nğŸ“ˆ Score Progress:")
        for i, review in enumerate(self.review_history, 1):
            score = review["average_score"]
            status = "âœ… TARGET REACHED" if score >= self.target_score else "ğŸ”„ In Progress"
            print(f"   Iteration {i}: {score:.2f}/10 - {status}")

        final_score = self.review_history[-1]["average_score"]
        improvement = final_score - self.review_history[0]["average_score"]

        print(f"\nğŸ¯ Final Score: {final_score:.2f}/10")
        print(f"ğŸ“Š Total Improvement: {improvement:+.2f} points")

        if final_score >= self.target_score:
            print(f"âœ… Successfully reached target score of {self.target_score}/10!")
        else:
            print(f"âš ï¸  Did not reach target score (current: {final_score:.2f}, target: {self.target_score})")
            print(f"   Consider running more iterations or adjusting target")

        # ä¿å­˜å®Œæ•´å†å²
        history_file = self.output_dir / "complete_history.json"
        with open(history_file, "w", encoding="utf-8") as f:
            json.dump(self.review_history, f, indent=2, ensure_ascii=False)

        print(f"\nğŸ’¾ Complete history saved: {history_file}")
        print(f"ğŸ“ All reports saved in: {self.output_dir}")


async def main():
    """ä¸»å‡½æ•°"""
    import sys

    if len(sys.argv) < 2:
        print("Usage: python iterative_code_improvement.py <code_directory> [target_score] [max_iterations]")
        print("\nExample:")
        print("  python iterative_code_improvement.py deepcode_lab/papers/1/generate_code 8.0 5")
        sys.exit(1)

    code_directory = sys.argv[1]
    target_score = float(sys.argv[2]) if len(sys.argv) > 2 else 8.0
    max_iterations = int(sys.argv[3]) if len(sys.argv) > 3 else 5

    improver = IterativeCodeImprover(
        code_directory=code_directory,
        target_score=target_score,
        max_iterations=max_iterations
    )

    await improver.run()


if __name__ == "__main__":
    asyncio.run(main())
